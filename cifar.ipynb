{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv as csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import _pickle as cPickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = cPickle.load(fo,encoding='latin1')\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = unpickle('cifar-10-batches-py/data_batch_1')\n",
    "batch_2 = unpickle('cifar-10-batches-py/data_batch_2')\n",
    "batch_3 = unpickle('cifar-10-batches-py/data_batch_3')\n",
    "batch_4 = unpickle('cifar-10-batches-py/data_batch_4')\n",
    "batch_5 = unpickle('cifar-10-batches-py/data_batch_5')\n",
    "\n",
    "test = unpickle('cifar-10-batches-py/test_batch')\n",
    "\n",
    "\n",
    "X_train = np.concatenate((batch_1['data'],\n",
    "                          batch_2['data'],\n",
    "                          batch_3['data'],\n",
    "                          batch_4['data'],\n",
    "                          batch_5['data']), axis=0)\n",
    "\n",
    "Y_train = np.concatenate((batch_1['labels'],\n",
    "                          batch_2['labels'],\n",
    "                          batch_3['labels'],\n",
    "                          batch_4['labels'],\n",
    "                          batch_5['labels']), axis=0)\n",
    "\n",
    "\n",
    "X_test = test['data']\n",
    "Y_test = np.asarray(test['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':['rbf'], 'C':[1, 10], 'degree':[1,2,3]}\n",
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "\n",
    "\n",
    "clf = GridSearchCV(clf, parameters, n_jobs=-1,verbose=1, cv=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
